{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wide model with sparse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('consus_test.csv', <http.client.HTTPMessage at 0x17fa95d6b70>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_file = tempfile.NamedTemporaryFile()\n",
    "# test_file = tempfile.NamedTemporaryFile()\n",
    "with urllib.request.urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\") as response, open('consus_train.csv','wb') as out_file:\n",
    "    data=response.read()\n",
    "    out_file.write(data)\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", 'consus_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CSV_COLUMNS = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "    \"income_bracket\"]\n",
    "train_df = pd.read_csv('consus_train.csv',names=CSV_COLUMNS, skipinitialspace=True )\n",
    "test_df = pd.read_csv('consus_test.csv',names=CSV_COLUMNS, skipinitialspace=True, skiprows=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels= (train_df['income_bracket'].apply(lambda x: '>50K' in x)).astype(int) \n",
    "test_labels= (test_df['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to Tnesor\n",
    "def input_fn(dataset, num_epochs=None, shuffle=True):\n",
    "    df_data=pd.read_csv(tf.gfile.Open(dataset),names=CSV_COLUMNS, skipinitialspace=True, engine='python', skiprows=1)\n",
    "    df_data=df_data.dropna(how='any', axis=0)\n",
    "    labels = (df_data['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)\n",
    "    return tf.estimator.inputs.pandas_input_fn(x=df_data, y=labels, num_epochs=num_epochs, shuffle=shuffle, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base categorical column\n",
    "# know the set of all possible feature values of a column and there are only a few of them,\n",
    "# Each key in the list will get assigned an auto-incremental ID starting from 0. \n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list('gender', ['Female', 'Male'])\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"education\", [\n",
    "        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "        \"Preschool\", \"12th\"\n",
    "    ])\n",
    "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"marital_status\", [\n",
    "        \"Married-civ-spouse\", \"Divorced\", \"Married-spouse-absent\",\n",
    "        \"Never-married\", \"Separated\", \"Married-AF-spouse\", \"Widowed\"\n",
    "    ])\n",
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"relationship\", [\n",
    "        \"Husband\", \"Not-in-family\", \"Wife\", \"Own-child\", \"Unmarried\",\n",
    "        \"Other-relative\"\n",
    "    ])\n",
    "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"workclass\", [\n",
    "        \"Self-emp-not-inc\", \"Private\", \"State-gov\", \"Federal-gov\",\n",
    "        \"Local-gov\", \"?\", \"Self-emp-inc\", \"Without-pay\", \"Never-worked\"\n",
    "    ])\n",
    "\n",
    "\n",
    "# don't know the set of possible values in advance\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"native_country\", hash_bucket_size=1000)\n",
    "\n",
    "# base continuous column\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")\n",
    "\n",
    "# Making Continuous Features Categorical through Bucketization\n",
    "age_buckets = tf.feature_column.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "\n",
    "# Intersecting Multiple Columns with CrossedColumn\n",
    "education_x_occupation = tf.feature_column.crossed_column(['education', 'occupation'], hash_bucket_size=1000)\n",
    "# keys = string or Categorical_column\n",
    "\n",
    "age_buckets_x_education_x_occupation = tf.feature_column.crossed_column(\n",
    "    [age_buckets, \"education\", \"occupation\"], hash_bucket_size=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpe9f4lzng\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Lei\\\\AppData\\\\Local\\\\Temp\\\\tmpe9f4lzng', '_keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "# define linear model \n",
    "base_columns = [\n",
    "    gender, native_country, education, occupation, workclass, relationship,\n",
    "    age_buckets]\n",
    "\n",
    "crossed_columns = [education_x_occupation, age_buckets_x_education_x_occupation, \n",
    "                   tf.feature_column.crossed_column(['native_country','occupation'], hash_bucket_size=1000)]\n",
    "                   \n",
    "feature_columns= base_columns+crossed_columns                  \n",
    "m=tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpe9f4lzng\\model.ckpt.\n",
      "INFO:tensorflow:loss = 69.3147, step = 1\n",
      "INFO:tensorflow:global_step/sec: 199.866\n",
      "INFO:tensorflow:loss = 25.6617, step = 101 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.205\n",
      "INFO:tensorflow:loss = 35.8934, step = 201 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.301\n",
      "INFO:tensorflow:loss = 30.2206, step = 301 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.831\n",
      "INFO:tensorflow:loss = 36.7884, step = 401 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.2\n",
      "INFO:tensorflow:loss = 27.7739, step = 501 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.262\n",
      "INFO:tensorflow:loss = 33.1913, step = 601 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.702\n",
      "INFO:tensorflow:loss = 44.075, step = 701 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.319\n",
      "INFO:tensorflow:loss = 41.0936, step = 801 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.812\n",
      "INFO:tensorflow:loss = 35.1304, step = 901 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.331\n",
      "INFO:tensorflow:loss = 35.0972, step = 1001 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.636\n",
      "INFO:tensorflow:loss = 27.9817, step = 1101 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.018\n",
      "INFO:tensorflow:loss = 39.1946, step = 1201 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.218\n",
      "INFO:tensorflow:loss = 37.7913, step = 1301 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.096\n",
      "INFO:tensorflow:loss = 37.2552, step = 1401 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.691\n",
      "INFO:tensorflow:loss = 35.477, step = 1501 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.977\n",
      "INFO:tensorflow:loss = 37.9704, step = 1601 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.696\n",
      "INFO:tensorflow:loss = 31.3233, step = 1701 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.68\n",
      "INFO:tensorflow:loss = 26.9226, step = 1801 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.967\n",
      "INFO:tensorflow:loss = 39.7222, step = 1901 (0.417 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpe9f4lzng\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 35.6438.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x17fad40f7f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training and Evaluating Our Model\n",
    "m.train(input_fn=input_fn('consus_train.csv'),steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-23-09:47:51\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpe9f4lzng\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-23-09:47:53\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.834101, accuracy_baseline = 0.763774, auc = 0.881853, auc_precision_recall = 0.69317, average_loss = 0.354358, global_step = 2000, label/mean = 0.236226, loss = 35.3945, prediction/mean = 0.229536\n"
     ]
    }
   ],
   "source": [
    "results = m.evaluate(input_fn = input_fn(dataset='consus_test.csv', num_epochs=1, shuffle=False), steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.834101 \n",
      "accuracy_baseline: 0.763774 \n",
      "auc: 0.881853 \n",
      "auc_precision_recall: 0.69317 \n",
      "average_loss: 0.354358 \n",
      "global_step: 2000 \n",
      "label/mean: 0.236226 \n",
      "loss: 35.3945 \n",
      "prediction/mean: 0.229536 \n"
     ]
    }
   ],
   "source": [
    "for key in sorted(results):\n",
    "    print('%s: %s ' %(key, results[key] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Regularization to Prevent Overfitting\n",
    "m= tf.estimator.LinearClassifier(feature_columns=feature_columns, \n",
    "                                 optimizer=tf.train.FtrlOptimizer(l2_regularization_strength=1.0,learning_rate=0.1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep model with dense columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Represents multi-hot representation of given categorical column.\n",
    "# indicator_column(categorical_column)\n",
    "deep_columns = [\n",
    "    tf.feature_column.indicator_column(workclass),\n",
    "    tf.feature_column.indicator_column(education),\n",
    "    tf.feature_column.indicator_column(gender),\n",
    "    tf.feature_column.indicator_column(relationship),\n",
    "    # _DenseColumn that converts from sparse\n",
    "    # embedding_column(categorical_column,dimension, \n",
    "    tf.feature_column.embedding_column(native_country, dimension =8),\n",
    "    tf.feature_column.embedding_column(occupation, dimension = 8),\n",
    "    age, \n",
    "    education_num,\n",
    "    capital_gain,\n",
    "    capital_loss,\n",
    "    hours_per_week]\n",
    "\n",
    "# the number of dimensions is to start with a value on the order of log2⁡(n) or k*n ** (0.25), \n",
    "# where n is the number of unique features in a feature column and k is a small constant (usually smaller than 10).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpnzqi95s2\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\Lei\\\\AppData\\\\Local\\\\Temp\\\\tmpnzqi95s2', '_keep_checkpoint_max': 5}\n"
     ]
    }
   ],
   "source": [
    "# Combining Wide and Deep Models into One\n",
    "\n",
    "m = tf.estimator.DNNLinearCombinedClassifier(linear_feature_columns=crossed_columns, \n",
    "                                             dnn_feature_columns=deep_columns, dnn_hidden_units=[100,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpnzqi95s2\\model.ckpt.\n",
      "INFO:tensorflow:loss = 66.9162, step = 1\n",
      "INFO:tensorflow:global_step/sec: 193.751\n",
      "INFO:tensorflow:loss = 54.2068, step = 101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.085\n",
      "INFO:tensorflow:loss = 44.7816, step = 201 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.225\n",
      "INFO:tensorflow:loss = 40.8512, step = 301 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.738\n",
      "INFO:tensorflow:loss = 52.2857, step = 401 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.532\n",
      "INFO:tensorflow:loss = 52.6999, step = 501 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.229\n",
      "INFO:tensorflow:loss = 41.6077, step = 601 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.685\n",
      "INFO:tensorflow:loss = 54.2148, step = 701 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.034\n",
      "INFO:tensorflow:loss = 48.9944, step = 801 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.945\n",
      "INFO:tensorflow:loss = 44.7112, step = 901 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.086\n",
      "INFO:tensorflow:loss = 57.8194, step = 1001 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.113\n",
      "INFO:tensorflow:loss = 41.2897, step = 1101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.137\n",
      "INFO:tensorflow:loss = 37.9752, step = 1201 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.95\n",
      "INFO:tensorflow:loss = 56.0785, step = 1301 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.341\n",
      "INFO:tensorflow:loss = 47.7641, step = 1401 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.59\n",
      "INFO:tensorflow:loss = 45.9871, step = 1501 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.295\n",
      "INFO:tensorflow:loss = 39.5764, step = 1601 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.16\n",
      "INFO:tensorflow:loss = 39.069, step = 1701 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.957\n",
      "INFO:tensorflow:loss = 45.101, step = 1801 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.333\n",
      "INFO:tensorflow:loss = 46.0209, step = 1901 (0.511 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpnzqi95s2\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 43.4742.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'float32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-23-10:26:09\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Lei\\AppData\\Local\\Temp\\tmpnzqi95s2\\model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-23-10:26:11\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.819606, accuracy_baseline = 0.763774, auc = 0.850696, auc_precision_recall = 0.681023, average_loss = 0.412041, global_step = 2000, label/mean = 0.236226, loss = 41.1561, prediction/mean = 0.245037\n",
      "accuracy: 0.819606\n",
      "accuracy_baseline: 0.763774\n",
      "auc: 0.850696\n",
      "auc_precision_recall: 0.681023\n",
      "average_loss: 0.412041\n",
      "global_step: 2000\n",
      "label/mean: 0.236226\n",
      "loss: 41.1561\n",
      "prediction/mean: 0.245037\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluating The Model\n",
    "m.train(input_fn=input_fn(dataset='consus_train.csv'), steps=2000)\n",
    "results = m.evaluate(input_fn=input_fn('consus_test.csv', num_epochs=1,shuffle=False), steps=None)\n",
    "for key in sorted(results):\n",
    "    print('%s: %s' %(key, results[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
